# Neural Network Interpretability

- A collection of infrastructure and tools for research in neural network interpretability in Tensorflow. [link](https://github.com/tensorflow/lucid)
- https://openai.com/blog/introducing-activation-atlases/
  - Can find out (by human judgement) that the NN model is "picking up on something that is correlated, but not causal, with the correct answer."

# Model-agnostic Interpretability

- Lime
- Shap
