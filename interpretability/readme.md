# Neural Network Interpretability

- Lucid: A collection of infrastructure and tools for research in neural network interpretability in Tensorflow. [link](https://github.com/tensorflow/lucid)

- Activation Atlases
  - https://openai.com/blog/introducing-activation-atlases/
  - Can find out (by human judgement) that the NN model is "picking up on something that is correlated, but not causal, with the correct answer."
  - keywords: **feature visualization**  

# Model-agnostic Interpretability

- Lime
- Shap
